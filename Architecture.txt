Architecture Overview
---------------------

The AI Voice Agent is designed with a client-server architecture, utilizing a React frontend for user interaction and a FastAPI backend for processing and integrating with external services. The system supports voice-based commands for sending emails, chatting with customers, and booking calls, with modular integrations for STT, TTS, LLMs, Gmail API, and LiveKit.

Components:
- Frontend (React):
  - Captures user voice input via the browser's microphone API.
  - Displays an editable popup for email content generated by the backend.
  - Provides a call interface powered by LiveKit.
  - Manages a chat interface for customer interactions.

- Backend (FastAPI):
  - Receives and processes voice inputs using configurable STT services (ElevenLabs, Cartesia, Deepgram).
  - Recognizes user intent using an LLM (Gemini as default, switchable to OpenAI).
  - Generates responses or content (e.g., emails) with the LLM.
  - Integrates with Gmail API for email sending.
  - Manages call functionality via LiveKit.
  - Converts text responses to speech using configurable TTS services (ElevenLabs, Cartesia, Deepgram).

External Services:
- STT: ElevenLabs, Cartesia, Deepgram (configurable).
- TTS: ElevenLab, Cartesia, Deepgram (configurable).
- LLMs: Gemini (primary), OpenAI (configurable).
- Email: Gmail API (requires credentials.json).
- Calls: LiveKit.

Configuration:
- Managed via `backend/app/core/config.py`.
- Allows seamless switching between STT, TTS, and LLM providers by updating configuration settings.

Data Flow:
1. User provides voice input through the frontend.
2. Frontend sends voice data to the backend.
3. Backend converts voice to text using the selected STT service.
4. Backend determines intent using the LLM.
5. Based on intent:
   - Email: Generates email content, sends it to the frontend for editing in a popup, then sends via Gmail API.
   - Call: Initiates a call using LiveKit, with the frontend managing the interface.
   - Chat: Generates a response with the LLM, converts it to speech with TTS, and sends it to the frontend.
6. Frontend updates the user interface with the results.




project-root/
├── backend/
│ ├── app/
│ │ ├── api/
│ │ │ ├── endpoints/
│ │ │ │ ├── voice.py # Voice input processing
│ │ │ │ ├── email.py # Email functionality
│ │ │ │ ├── call.py # Call management
│ │ │ │ └── chat.py # Chat functionality
│ │ │ └── deps.py # API dependencies
│ │ ├── core/
│ │ │ ├── config.py # Configuration for STT, TTS, LLMs
│ │ │ ├── stt.py # STT service integration
│ │ │ ├── tts.py # TTS service integration
│ │ │ ├── llm.py # LLM integration
│ │ │ └── intent.py # Intent recognition logic
│ │ ├── services/
│ │ │ ├── gmail_service.py # Gmail API integration
│ │ │ └── livekit_service.py # LiveKit integration
│ │ └── main.py # FastAPI entry point
│ ├── tests/ # Unit and integration tests
│ └── requirements.txt # Python dependencies
├── frontend/
│ ├── public/ # Static files
│ ├── src/
│ │ ├── components/
│ │ │ ├── VoiceCapture.js # Voice input component
│ │ │ ├── EmailPopup.js # Editable email popup
│ │ │ ├── CallInterface.js # LiveKit call interface
│ │ │ └── ChatInterface.js # Chat interface
│ │ ├── services/
│ │ │ └── api.js # Backend API client
│ │ ├── App.js # Main React component
│ │ └── index.js # React entry point
│ ├── package.json # Node.js dependencies
│ └── .env # Frontend environment variables
├── credentials.json # Gmail API credentials
├── README.md # Project documentation
├── architecture.txt # Architecture details
└── appflow.txt # Application flow details
